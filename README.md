# DocAtlas
# ğŸ“„ Retrieval-Augmented Generation (RAG) Application  
A full-stack AI system that enables intelligent querying over uploaded documents using **semantic search**, **vector embeddings**, and **LLM-powered responses**.

This project demonstrates a production-grade RAG architecture with end-to-end functionality: document ingestion, background processing, vector indexing, retrieval, and contextual answer generation.

---

## ğŸš€ Tech Stack

### **Frontend**
- React  
- Axios  
- Tailwind (optional)

### **Backend**
- Node.js  
- Express  
- BullMQ (Redis) for background jobs  
- OpenAI API for LLM responses  
- Sentence Transformers for embedding generation  

### **Databases**
- **MongoDB** â†’ stores metadata, file info, chat history  
- **Qdrant** â†’ vector database for similarity search  

### **Models**
- **nomic-embed-text-v1.5-large** (Sentence Transformers)

---

## ğŸ“¦ Features

### âœ… **1. Document Upload**
- Upload PDFs, text files, and documents from frontend  
- Stores metadata in MongoDB  
- Pushes files to BullMQ queue for processing  

### âœ… **2. Background File Processing**
- Worker service extracts text  
- Generates embeddings using Sentence Transformers  
- Chunks document into segments  
- Inserts vectors + metadata into Qdrant  

### âœ… **3. Semantic Search & Context Retrieval**
- Uses HNSW indexing in Qdrant  
- Retrieves top-K relevant chunks for each user query  

### âœ… **4. LLM-Generated Answers**
- Sends query + retrieved context to OpenAI  
- Produces grounded, context-aware answers  
- Reduces hallucination compared to plain LLM usage  

### âœ… **5. Full Chat Interface (Frontend)**
- Clean UI for chatting  
- File upload interface  
- Displays AI answer + supporting document chunks  

### âœ… **6. Modular Architecture**
Easily replaceable components:
- Embedding model  
- LLM provider  
- Vector database  
- File processing logic  

---

## ğŸ§  System Architecture

User â†’ React UI â†’ Express API â†’ Query
â†“
Qdrant Vector Search â† Embeddings
â†“
Retrieved Document Chunks
â†“
OpenAI GPT (LLM) â† Prompt + Context â†’ Final Answer

## Project Structure
## â”œâ”€â”€ backend
## â”‚ â”œâ”€â”€ src
## â”‚ â”‚ â”œâ”€â”€ routes
## â”‚ â”‚ â”œâ”€â”€ controllers
## â”‚ â”‚ â”œâ”€â”€ services
## â”‚ â”‚ â”‚ â”œâ”€â”€ ragService.js
## â”‚ â”‚ â”‚ â”œâ”€â”€ embeddingService.js
## â”‚ â”‚ â”‚ â”œâ”€â”€ qdrantService.js
## â”‚ â”‚ â”œâ”€â”€ workers
## â”‚ â”‚ â”‚ â””â”€â”€ fileProcessor.js
## â”‚ â”‚ â””â”€â”€ utils
## â”‚ â””â”€â”€ app.js
---
##â”œâ”€â”€ frontend
## â”‚ â”œâ”€â”€ src
## â”‚ â”‚ â”œâ”€â”€ components
## â”‚ â”‚ â”œâ”€â”€ assest
## â”‚ â”‚ â”œâ”€â”€ pages
## â”‚ â””â”€â”€ App.js
## â”‚
## â””â”€â”€ README.md
